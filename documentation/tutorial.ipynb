{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a87c992",
   "metadata": {},
   "source": [
    "# LightHearted: Tutorial\n",
    "\n",
    "This notebook presents a walkthrough of how to use the LightHearted framework to create a lighting design. For this, we use the design employed in a concert with the Aarhus Symphony Orchestra (ASO) for a performance of Tchaikovsky's Romeo and Juliet Fantasy Overture. The script containing this can be found in the examples folder . By the end of this tutorial you should hopefully be familiar with the use of the five main objects used in a LightHearted workflow:\n",
    "\n",
    "- FIFOBuffer - Used to contain and process ECG signals\n",
    "- LightingArray - Used to define a lighting group and send them commands\n",
    "- MappingArray - Used to contain and reduce data to be mapped from multiple ECG devices and derive spatial expansions that can be mapped to LightingArrays\n",
    "- ContinuousMapper - Used to define the relationship between a MappingArray and a LightingArray\n",
    "- TriggerMapper - Used to define event based triggers between FIFOBuffers and LightingArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec4e661",
   "metadata": {},
   "source": [
    "## 1. Basics\n",
    "\n",
    "### 1.1 Workflow\n",
    "\n",
    "The general workflow for LightHearted is as follows:\n",
    "\n",
    "1. ECG signals are transported over OSC and received in a script. For each signal, a first-in-first-out (FIFO) buffer is instanced.\n",
    "2. Optional chains of transforms are applied to each FIFOBuffer, and placed into new instances of FIFOBuffers (e.g. filtering, QRS extraction).\n",
    "3. Signal or transformed buffers can be assigned to instances of MappingArrays. These take multiple FIFOBuffers, with their position in the array corresponding to a spatial position. Each buffer is reduced to a single value using a chain of functions (e.g. mean, the newest value in the array).\n",
    "4. The MappingArray can be used to generate spatial expansions, that is expanding the MappingArray to match the shape of a LightingArray. This can be done through a user-defined function (e.g. linear interpolation, filling the expansion with set values). A single MappingArray can generate multiple spatial expansions if the data is to be used to generate lighting across multiple lighting groups.\n",
    "5. Groups of lighting fixtures are defined as LightingArray objects. If interpolations are to be used to generate spatial expansions in the MappingArray, anchor positions in the LightingArray can also be defined. These correspond to the spatial positions of the values in the MappingArray before expansion.\n",
    "6. ContinuousMappers can be instanced to define the relationship between the MappingArrays/spatial expansions and the LightingArrays. These result in the intensity and colour parameters of the LightingArray being continuously updated.\n",
    "7. The LightingArray can be used to send commands to the installed lighting system in the concert hall, sending the corresponding parameter messages to the fixtures.\n",
    "8. TriggerMapper objects can be defined to generate action based mappings between FIFOBuffers. These take one buffer as a reference and another as a query (e.g. a signal buffer could be a reference, and a buffer of peaks indices could be a query). A chain of trigger functions can be defined, as long as the final function returns a bool (e.g. has a peak index in the peak buffer crossed a specified index in the signal buffer). Upon return of a True value from the trigger function chain, an action function is triggered.\n",
    "\n",
    "These should be implemented in a single script, encapsulated in async functions. Familiarity with the asyncio library is assumed. If there are many parameters to define, it is also recommeded to make use of a config script, which is imported into the main script.\n",
    "\n",
    "### 1.2 The ASO Design\n",
    "\n",
    "The ASO design consists of three primary lighting groups and corresponding mappings:\n",
    "\n",
    "1. A group of 14 horizonally organised LEDs reflected from the organ directly behind the stage. For this, we derive heart rate values from the ECG signals, interpolate the values to match the number of LEDs, and use these to drive shifts in RGB values within a defined colourmap. We also use the detection of an R-Peak to trigger changes in the lighting intensity.\n",
    "2. A group of 36 baluster leds, mounted in the balconies around the audience. For these, we use the derived heart rate from the conductor's ECG to generate shifts in RGB within the colourmap.\n",
    "3. A horizontally arranged row of 15 background LEDs, mounted in the wall to the rear of the stage. We use these to display the current colourmap.\n",
    "\n",
    "A video of the design in action can be found [here](https://osf.io/c2zt9/?view_only=23cc8068eba347b2a7cc4f6dbc77adc3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15542e5c",
   "metadata": {},
   "source": [
    "# 2. First Steps\n",
    "\n",
    "## 2.1 Setting Up a Script\n",
    "\n",
    "The first step is to create a new script, which we will call ASO25.py. At first, we will just import asyncio, used to define our async functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aced24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f98f6ad",
   "metadata": {},
   "source": [
    "We will then define a main function, and set it to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2764503",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a342ba41",
   "metadata": {},
   "source": [
    "We will define separate processing functions, and these will be launched from the main function. We will also initialise all of our LightHearted objects here.\n",
    "\n",
    "The next step is to define identifiers for each of the ECG signals that we will use. It is important to note that these identifiers will be used across the design, e.g. as osc addresses, as dictionary keys, and data labels. For the purposes of this example, we will use four ECG signals - from the conductor, the french horn, the concertmaster, and an audience member. We will labels these ```\"conductor\"```, ```\"brs\"```, ```\"vn1\"```, and ```\"aud\"``` respectively. We will define them as a list ```osc_addresses```, as there first use will be in the reception of the ECG data over OSC. We can place this line in the main function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad04d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "osc_addresses = [\"/aud\", \"/brs\", \"/conductor\", \"/vn1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c605879b",
   "metadata": {},
   "source": [
    "## 2.2 Getting Data Into the Script\n",
    "\n",
    "The next step is to start receiving data in the script. We can either receive data from four ECG devices over OSC, or we can use the ```csv_simulator``` to read recorded ECG csv files in realtime. We will walk through both of these.\n",
    "\n",
    "### 2.2.1 Sending Data from an ECG Sensor\n",
    "\n",
    "LightHearted is intented to be device agnostic, that is that it can function with any ECG device. In view of this, ECG data is expected to be received over OSC messages. Currently, LightHearted contains inbuilt support for devices from [SIFILabs](https://sifilabs.com/). This can be accessed through running the script ```sifilabs.py``` in the ```acquisition``` module. This will connect to and stream an arbritrary number of SIFILabs devices over OSC.\n",
    "\n",
    "The script is parameterised in ```sificonfig.py```. The most important variable here is the ```mac_dict```, which provides the device identifier and MAC address. It is important to note that the keys in the ```mac_dict``` should match the OSC addresses set in the LightHearted design. So in our case, we would parameterise it as so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2f0559",
   "metadata": {},
   "outputs": [],
   "source": [
    "mac_dict = { \n",
    "    \"/aud\": \"MACADDRESS1\",\n",
    "    \"/brs\": \"MACADDRESS2\",\n",
    "    \"/conductor\": \"MACADDRESS3\",\n",
    "    \"/vn1\": \"MACADDRESS4\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3568b6",
   "metadata": {},
   "source": [
    "The IP and port of the server receiving the data (in our case to be used in our design) are also set here in the ```sifi_receiver_ip``` and ```sifi_receiver_port``` variables.\n",
    "\n",
    "### 2.2.2 Reading a CSV File in Realtime\n",
    "\n",
    "LightHearted also supports the use of previously recorded ECG data. This is done through the ```csv_simulator``` module. All the csv files should be placed in a single directory, and importantly, their names should match the OSC addresses specified above. In our case, our four csv files should be named:\n",
    "\n",
    "- ```aud.csv```\n",
    "- ```brs.csv```\n",
    "- ```conductor.csv```\n",
    "- ```vn1.csv```\n",
    "\n",
    "The reader is parameterised through ```sim_config.py```. The ```filepath``` variable specifies the directory in which the csv files are located. If ```None``` is provided, this defaults to the ```csv``` directory. The ```column``` specifies the column of the csv to read from. The ```csv_sr``` set the speed of playback.\n",
    "\n",
    "Both of these methods can be integrated into a LightHearted script by calling them as a process within the script. In our case, we will use the csv_reader and define a function where it can run on the press of the ```'r'``` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0f8ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aioconsole\n",
    "from multiprocessing import Process\n",
    "from csv_simulator.csv_simulator import csv_sim\n",
    "\n",
    "async def listen_for_commands() -> None:\n",
    "    \"\"\"\n",
    "    Asynchronously listens for user commands from the console.\n",
    "    - 'q': Cancels all running tasks and stops the event loop (quits the program).\n",
    "    - 'r': Starts the CSV simulator in a separate process.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        user_input = await aioconsole.ainput(\"Enter 'r' to run simulator: \")\n",
    "        if user_input.lower() == 'r':\n",
    "            p_csv = Process(target=csv_sim)\n",
    "            p_csv.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d9a451",
   "metadata": {},
   "source": [
    "In our main block, we now define a task for the listener."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f59e0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "\n",
    "    task_commands = asyncio.create_task(listen_for_commands())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ae856",
   "metadata": {},
   "source": [
    "We will now be able to launch the csv reader on the press of the ```'r'``` key.\n",
    "\n",
    "### 2.2.3 Receiving Data in the Script\n",
    "\n",
    "So how do we receive this data in our script? There are several inbuilt functions to setup an osc server and process incoming data. However, first we need to initialise a location for the data to be placed. This is where we are introduced to the first key object for a LightHearted design - the ```FIFOBuffer``` object. This is a buffer of a fixed size, which operates on a first-in-first-out principle, meaning that as data is added to the buffer that exceeds the buffer length, the oldest data in the buffer is deleted. We instantiate the buffer with a single argument, the size of the buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3248a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from acquisition.fifo_buffer import FIFOBuffer\n",
    "\n",
    "buffer = FIFOBuffer(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5692258",
   "metadata": {},
   "source": [
    "We can add data to the buffer using the ```enqueue``` method. ```Int```, ```Float```, ```List```, ```Tuple``` and ```np.ndarray``` are accepted as valid to enqueue. Lists, tuples, and numpy arrays are flattened before they are enqueued. The ```get_buffer``` method returns the current buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a82e3e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int: [1.]\n",
      "float: [1.  1.5]\n",
      "list: [1.  1.5 2.  3.  4. ]\n",
      "tuple: [1.  1.5 2.  3.  4.  5.  6. ]\n",
      "np.ndarray: [1.  1.5 2.  3.  4.  5.  6.  7.  8.  9. ]\n",
      "FIFO (1 is removed, 10 is added): [ 1.5  2.   3.   4.   5.   6.   7.   8.   9.  10. ]\n"
     ]
    }
   ],
   "source": [
    "# int\n",
    "buffer.enqueue(1)\n",
    "print(f\"int: {buffer.get_buffer()}\")\n",
    "# float\n",
    "buffer.enqueue(1.5)\n",
    "print(f\"float: {buffer.get_buffer()}\")\n",
    "# list\n",
    "buffer.enqueue([2, 3, 4])\n",
    "print(f\"list: {buffer.get_buffer()}\")\n",
    "# tuple\n",
    "buffer.enqueue((5, 6))\n",
    "print(f\"tuple: {buffer.get_buffer()}\")\n",
    "# np.ndarray\n",
    "import numpy as np\n",
    "buffer.enqueue(np.array([7, 8, 9]))\n",
    "print(f\"np.ndarray: {buffer.get_buffer()}\")\n",
    "\n",
    "# first in, first out\n",
    "buffer.enqueue(10)\n",
    "print(f\"FIFO (1 is removed, 10 is added): {buffer.get_buffer()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea02864",
   "metadata": {},
   "source": [
    "The buffer can be cleared with the ```clear_buffer``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eac04c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer after clearing: []\n"
     ]
    }
   ],
   "source": [
    "buffer.clear_buffer()\n",
    "print(f\"Buffer after clearing: {buffer.get_buffer()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eb7566",
   "metadata": {},
   "source": [
    "The ```set_buffer``` method clears and sets the buffer to the current values. The ```resize_buffer``` argument can reset the fixed length of the buffer to the new input. ```get_size``` returns the current size of the buffer and ```get_max_size``` returns the fixed length. ```is_full``` returns a boolean if the the buffer has reached its fixed length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2134a044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer after enqueing: [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "\n",
      "\n",
      "Buffer after setting: [0. 1. 2. 3. 4.]\n",
      "Buffer size: 5\n",
      "Buffer max size: 10\n",
      "Is buffer full? False\n",
      "\n",
      "\n",
      "Buffer after setting with resize: [0. 1. 2. 3. 4.]\n",
      "Buffer size after resize: 5\n",
      "Buffer max size after resize: 5\n",
      "Is buffer full after resize? True\n"
     ]
    }
   ],
   "source": [
    "buffer.enqueue(np.arange(10))\n",
    "print(f\"Buffer after enqueing: {buffer.get_buffer()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "buffer.set_buffer(np.arange(5), resize_buffer=False)\n",
    "print(f\"Buffer after setting: {buffer.get_buffer()}\")\n",
    "print(f\"Buffer size: {buffer.get_size()}\")\n",
    "print(f\"Buffer max size: {buffer.get_max_size()}\")\n",
    "print(f\"Is buffer full? {buffer.is_full()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "buffer.set_buffer(np.arange(5), resize_buffer=True)\n",
    "print(f\"Buffer after setting with resize: {buffer.get_buffer()}\")\n",
    "print(f\"Buffer size after resize: {buffer.get_size()}\")\n",
    "print(f\"Buffer max size after resize: {buffer.get_max_size()}\")\n",
    "print(f\"Is buffer full after resize? {buffer.is_full()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Aarhus_Interactive_Lighting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
